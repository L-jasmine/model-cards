{
    "id": "liminerity/Mistral-quiet-star-ascii-demo-gguf",
    "status": "init",
    "model_type": "unknown",
    "name": "",
    "summary": "",
    "author": {
        "name": "liminerity",
        "url": "",
        "description": ""
    },
    "size": "",
    "requires": "",
    "released_at": "2024-03-30T00:49:45Z",
    "architecture": "",
    "files": [
        {
            "name": "expressive-gguf-unsloth.Q4_K_M.gguf",
            "size": "4368439072",
            "quantization": "Q4_K_M",
            "tags": [],
            "sha256": "c3c34e375e9c6f08e6646143616a636792e1b8c2ffe23d4a067907ce53a26104",
            "download": {
                "default": "https://huggingface.co/liminerity/Mistral-quiet-star-ascii-demo-gguf/resolve/main/expressive-gguf-unsloth.Q4_K_M.gguf"
            }
        },
        {
            "name": "expressive-gguf-unsloth.Q8_0.gguf",
            "size": "7695857376",
            "quantization": "Q8_0",
            "tags": [],
            "sha256": "95f22af25d7a38bff9df1c4a9d14208a539efa4c6ef76b1e5085d85821f9dba4",
            "download": {
                "default": "https://huggingface.co/liminerity/Mistral-quiet-star-ascii-demo-gguf/resolve/main/expressive-gguf-unsloth.Q8_0.gguf"
            }
        }
    ],
    "prompt_template": "",
    "reverse_prompt": "",
    "context_size": 0,
    "vector_size": 0,
    "metrics": {}
}